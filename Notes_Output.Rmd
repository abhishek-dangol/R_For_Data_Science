---
title: "R_For_Data_Science_Notes"
author: "Abhishek Dangol"
date: "12/30/2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The mpg data frame
First we need to load the ggplot2 package. 'mpg' is a dataset in the ggplot2 library.
```{r, cache=TRUE, message=FALSE}
library(ggplot2)
mpg
```
We want to find out if cars with bigger engines consume more gas. The geom_point() adds a layer of points to the plot (scatterplot)
Each geom function in ggplot takes a mapping as argument. This defines how variables in dataset are mapped to visual properties.
The mapping argument is always paired with aes() and the x and y arguments of aes() specify which variables to map to the x and y axes.
```{r, cache=TRUE, message=FALSE}
ggplot(data=mpg) + geom_point(mapping = aes(x = displ, y = hwy))
```

## Aesthetic mapping
We can map the colors of our points to the 'class' variable to reveal the class of each car.
As we cam see the red dots are sports cars and hence, they have better mileage despite having bigger engines.
```{r, cache=TRUE, message=FALSE}
ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class))
```
Alternatively, we can also map class to the alpha aesthetic which controls the transparency of the points or to the shape aesthetic which
controls the shape of the points/
```{r, cache=TRUE, message=FALSE}
ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, alpha = class))
ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, shape = class))
```
We can also set the aesthetic property of the geom manually. For example, we can make all of the points in our plot blue.
```{r, cache=TRUE, message=FALSE}
ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), color = "blue")
```

## Facets
Another way, particularly useful for categorical variables is to split the plot into facets - subplots that each display one subset of the data.
Use facet_wrap(). The first argument of facet_wrap() should be a formula which we can create with ~ followed by a variable name. 
```{r, cache=TRUE, message=FALSE}
ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ class, nrow = 2)
```


To facet the plot on the combination of two variables, add facet_grid() to plot call. To plot on the basis fo 'drv' and 'cyl'
```{r, cache=TRUE, message=FALSE}
ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ cyl)
```

There are several different kinds of geoms such as bar geoms, line geoms, boxplot geoms, point geoms (as seen above) and smooth geom (as shown below)
```{r, cache=TRUE, message=FALSE}
ggplot(data = mpg) + geom_smooth(mapping = aes(x = displ, y = hwy))
```

We can also set the linetype of a line. geom_smooth() will  draw a different line, with a different linetype, for each unique value of the variable
that you map to linetype.
```{r, cache=TRUE, message=FALSE}
ggplot(data = mpg) + geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv, color = drv))
```

To display multple geoms in the same plot, add multiple geom functions to ggplot()```{r}
```{r, cache=TRUE, message=FALSE}
ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + geom_smooth(mapping = aes(x = displ, y = hwy))
```

We can get rid of the duplication by using the following code instead
```{r, cache=TRUE, message=FALSE}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point() + geom_smooth()
```

If we were to add a mapping tpa a geom function, it will add it to that layer only. This makes it possible to display different aesthetics in 
different layers
```{r, cache=TRUE, message=FALSE}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(mapping = aes(color = class)) + geom_smooth()
```

We can also specify data for each layer. Here, our smooth line displays just a subset of the mpg dataset, the subcompact cars. The local argument in geom_smooth()
overrides the global argument in ggplot() for that layer only. We need to load dplyr package for the filter() function to work.
```{r, cache=TRUE, message=FALSE}
library(dplyr)
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(mapping = aes(color = class)) + geom_smooth(data = filter(mpg, class == "subcompact"), se = FALSE)
```

## STATISTICAL TRANSFORMATIONS

Even though we did not specify the y axis in the bar chart below, R can  automatically calculate new values for the graph using stat or statistical transformations.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut))
```

The default value for stat in geom_bar is count. We can interchangeably use stat_count() and geom_bar().
```{r, cache=TRUE, message=FALSE}
ggplot(data = diamonds) + stat_count(mapping = aes(x = cut))
```

We can also override the default stat. Here we are using 'identity' instead of the default 'count'. Also, we can display a bar chart of proportion rather than count
```{r, cache=TRUE, message=FALSE}
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = ..prop.., group = 1))
```

`stat_summary()` summarizes the y values for each unique x value, to draw attention to the summary that we are computing
```{r, cache=TRUE, message=FALSE}
ggplot(data = diamonds) + stat_summary(
  mapping = aes(x = cut, y = depth),
  fun.ymin = min,
  fun.ymax = max,
  fun.y = median
)
```

## POSITION ADJUSTMENT

We can color a bar chart using either colour aesthetic or more usefully fill.
```{r, cache=TRUE, message=FALSE}
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, color = cut))
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = cut))
```

If we were to map the fill aesthetic to another variable like clarity, the bars are automatically stacked. Each colored rectangle represents a combination of cut
and clarity
```{r, cache=TRUE, message=FALSE}
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity))
```

`position = "identity"` places each object exactly where it falls in the context of the graph. In bars, however, to see the overlapping we either need to make the bars slightly transparent by setting alpha to a small value, or completely transparent by setting `fill = NA`.
```{r, cache=TRUE, message=FALSE}
ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + geom_bar(alpha = 1/5, position = "identity")
ggplot(data = diamonds, mapping = aes(x = cut, color = clarity)) + geom_bar(fill = NA, position = "identity")
```

`position = "dodge"` places overlapping objects directly beside one another. This makes it easier to compare individual values
```{r, cache=TRUE, message=FALSE}
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity), position = "dodge")
```

`position = "jitter` adds a small amount of random noise to each point. This spreads the points out because no two points are likely to receive  the same amount of random noise
```{r, cache=TRUE, message=FALSE}
ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), position = "jitter")
```

## COORDINATE SYSTEMS

`coord_flip()` switches the x and y axes. This is useful for horizontal boxplots and for long labels
```{r, cache=TRUE, message=FALSE}
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() + coord_flip()
```

# DATA TRANSFORMATION
```{r, cache=TRUE, message=FALSE, warning=FALSE}
library(nycflights13)
library(tidyverse)
flights
```

## Filter rows with `filter()`
`filter()` allows us to subset observations based on their values. The first argument is the name of the data frame. The second and subsequent arguments are the expressions that filter the data frame. For example, we can select all flights on January 1st with:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
filter(flights, month == 1, day == 1)
```

`filter(flights, month == 11 | month == 12)` finds all flights that departed either in November or December
`nov_dec <- filter(flights, month %in% c(11, 12))` also does the same thing.

## Missing Values
`filter()` only includes rows where the condition is true; it excludes both false and NA values. If we want to preserve these missing values, we need to ask for them explicitly.

## Arrange rows with `arrange()`
`arrange()` works similarly to filter() except that instead of selecting rows, it changes their order. 
```{r, cache=TRUE, message=FALSE, warning=FALSE}
arrange(flights, year, month, day)
```

Use 'desc()` to re-order a column in descending order
```{r, cache=TRUE, message=FALSE, warning=FALSE}
arrange(flights, desc(dep_delay))
```

## Select columns with `select()`
Select columns by name
```{r, cache=TRUE, message=FALSE, warning=FALSE}
select(flights, year, month, day)
```

Select all columns between year and day (inclusive)
```{r, cache=TRUE, message=FALSE, warning=FALSE}
select(flights, year:day)
```

Select all columns except those from year to day (inclusive)
```{r, cache=TRUE, message=FALSE, warning=FALSE}
select(flights, -(year:day))
```

`starts_with("abc")` matches names that begin with "abc".
`ends_with("xyz")` matches names that end with "xyz".
`contains("xyz")` matches names that contain "xyz".
`matches("(.)\\1")` selects variables that match a regular expression.
`num_range("x", 1:3)` matches x1. x2 and x2.

`rename()` can be used to rename a variiable
```{r, cache=TRUE, message=FALSE, warning=FALSE}
rename(flights, tail_num = tailnum)
```

Using `select()` with `everything()` helper allows us to move variables to the start of the data frame.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
select(flights, time_hour, air_time, everything())
```

## Add new variables with mutate()

It is often useful to add new columns that are functions of existing columns
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights_small <- select(flights, year:day, ends_with("delay"), distance, air_time)
mutate(flights_small, gain = dep_delay - arr_delay, speed = distance / air_time * 60)
```

We can also refer to columns that we have just created
```{r, cache=TRUE, message=FALSE, warning=FALSE}
mutate(flights_small, gain = dep_delay - arr_delay, hours = air_time / 60, gain_per_hour = gain / hours)
```

If we only want to keep the new variables, use transmute()
```{r, cache=TRUE, message=FALSE, warning=FALSE}
transmute(flights, gain = dep_delay - arr_delay, hours = air_time / 60, gain_per_hour = gain / hours)

```

## Grouped summaries with summarise()

`summarise()` collapses a dataframe to a single row.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
```

`summarise()` is only useful if we pair it with `group_by()`. To get the average delay per date:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
by_day <- group_by(flights, year, month, day)
summarise(by_day, delay = mean(dep_delay, na.rm = TRUE))
```

## Combining multiple operations with pipe

We want to explore the relationship between the distance and average delay for each location. Our initial solution (without piping) would look like this:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
by_dest <- group_by(flights, dest)
delay <- summarise(by_dest, count = n(), dist = mean(distance, na.rm = TRUE), delay = mean(arr_delay, na.rm = TRUE))
delay <- filter(delay, count > 20, dest != "HNL")

# It looks like delays increase with distance up to ~750 miles and then decreases. This could be because as flights get longer there is more ability to make up for delays in the air

ggplot(data = delay, mapping = aes(x = dist, y = delay)) + geom_point(aes(size = count), alpha = 1/3) + geom_smooth(se = FALSE)
```

Using pipes, we can more efficiently write the code as:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
delays <- flights %>%
  group_by(dest) %>%
  summarise(
    count = n(),
    dist = mean(distance, na.rm = TRUE),
    delay = mean(arr_delay, na.rm = TRUE)
  )%>%
  filter(count > 20, dest != "HNL")
  
```

## Missing values

If we do not set the missing values:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights %>%
  group_by(year, month, day) %>%
  summarise(mean = mean(dep_delay))
```

If we do set the missing values:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights %>%
  group_by(year, month, day) %>%
  summarise(mean = mean(dep_delay, na.rm = TRUE))
```

In the case where missing values represent cancelled flights, we could also first of all remove the cancelled flights.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
not_cancelled <- flights %>%
  filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>% 
  group_by(year, month, day) %>%
  summarise(mean = mean(dep_delay))
```

## Count
To look at planes (identified by their tail number) that have the highest average delays.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
delays <- not_cancelled %>%
  group_by(tailnum) %>%
  summarise(
    delay = mean(arr_delay)
  )
```
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = delays, mapping = aes(x = delay)) + geom_freqpoly(binwidth = 10)
```

To view when the first and last flights leave each day:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(
    first = min(dep_time),
    last = max(dep_time)
  )
```

`n()` takes no arguments and returns the size of the current group. To count the number of non-missing values, use `sum(!is.na(x))`. To count the number of distinct or unique values, use `n_distinct(x)`.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
# which destination has the most carriers
not_cancelled %>%
  group_by(dest) %>%
  summarise(carriers = n_distinct(carrier)) %>%
  arrange(desc(carriers))
```
Counts are so useful that dplyr provides a simple helper if all we want is count
```{r, cache=TRUE, message=FALSE, warning=FALSE}
not_cancelled %>%
  count(dest)
```

A weight variable is used if want to for example, count(sum) the total number of miles a plane flew
```{r, cache=TRUE, message=FALSE, warning=FALSE}
not_cancelled %>%
  count(tailnum, wt = distance)
```

How many flights left before 5 am?
```{r, cache=TRUE, message=FALSE, warning=FALSE}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(n_early = sum(dep_time < 500))
```

What proportion of flights are delayed by more than one hour?
```{r, cache=TRUE, message=FALSE, warning=FALSE}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(hour_perc = mean(arr_delay > 60))
```

## Grouping by multiple variables

```{r, cache=TRUE, message=FALSE, warning=FALSE}
daily <- group_by(flights, year, month, day)
(per_day <- summarise(daily, flights = n()))
```

```{r, cache=TRUE, message=FALSE, warning=FALSE}
per_month <- summarise(per_day, flights = sum(flights))
per_year <- summarise(per_month, flights = sum(flights))
```


## Ungrouping
```{r, cache=TRUE, message=FALSE, warning=FALSE}
daily %>%
  ungroup() %>%
  summarise(flights = n())
```

## Grouped mutates and filters
Find the worst members of each group
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights_small %>%
  group_by(year, month, day) %>%
  filter(rank(desc(arr_delay)) < 10)
```

Find all the groups bigger than a threshold
```{r, cache=TRUE, message=FALSE, warning=FALSE}
popular_dests <- flights %>%
  group_by(dest) %>%
  filter(n() > 365)
popular_dests
```

Standardise to compute per group metrics
```{r, cache=TRUE, message=FALSE, warning=FALSE}
popular_dests %>%
  filter(arr_delay > 0) %>%
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>%
  select(year:day, dest, arr_delay, prop_delay)
```


# EXPLORATORY DATA ANALYSIS

Categorical variables can only take a small set of values. In R, categorical variables are usually saved as factors or character vectors.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut))
```

Continuous variables can take any of an infinite set of ordered values. Numbers and date-times are two examples of continuous variables.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = diamonds) + geom_histogram(mapping = aes(x = carat), binwidth = 0.5)

```

We should explore a variety of binwidths when working with histograms, as different binwidths can reveal different patters. For example, here is how the graph above looks when we zoom into just the diamonds with a size of less than three carats and choose a smaller binwidth.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
smaller <- diamonds %>%
  filter(carat < 3)
ggplot(data = smaller, mapping = aes(x = carat)) + geom_histogram(bindwidth = 0.1)
```

`geom_freqpoly()` performs the same calculation as `geom_histogram()` but instead of displaying the counts with bars, uses lines instead. It is much easier to understand overlapping lines than bars
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = smaller, mapping = aes(x = carat, color = cut)) + geom_freqpoly(binwidth = 0.1)
```

```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = smaller, mapping = aes(x = carat)) + geom_histogram(binwidth = 0.01)
```


## Outliers
The only evidence of outliers is the unusually wide limits on the x-axis
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5)

```

To be able to see the outliers, we need to zoom to small values of the y-axis with `coord_cartesian()`
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) + coord_cartesian(ylim = c(0, 50))
```

This allows us to see that there are three unusual values: 0, 30 and 60. We can pluck them out with dplyr
```{r, cache=TRUE, message=FALSE, warning=FALSE}
unusual <- diamonds %>%
  filter(y < 3 | y > 20) %>%
  select(price, x, y, z) %>%
  arrange(y)
unusual
```

If we encounter unusual values in the dataset, we have two options:
1. Drop the entire row with the strange values
```{r, cache=TRUE, message=FALSE, warning=FALSE}
diamonds2 <- diamonds %>%
  filter(between(y, 3, 20))
diamonds2
```
2. But the recommended way is to replace the unusual values with missing values. The easiest way to do this is to use `mutate()` to replace the variable with a modified copy. We can use `ifelse()` function to replace unsusual values with NA;
```{r, cache=TRUE, message=FALSE, warning=FALSE}
diamonds2 <- diamonds %>%
  mutate(y = ifelse(y < 3 | y > 20, NA, y))
```

We might want to compare the scheduled departure times for cancelled and non cancelled times. We can do this by making a new variable with `is.na()`
```{r, cache=TRUE, message=FALSE, warning=FALSE}
nycflights13::flights %>%
  mutate(
    cancelled = is.na(dep_time), 
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + sched_min / 60
  )%>%
  ggplot(mapping = aes(sched_dep_time)) + geom_freqpoly(mapping = aes(color = cancelled), binwidth = 1/4)
```

## Covariation

We want to explore how the price of a diamond varies with quality. Instead of displaying count, we will display density
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) + geom_freqpoly(mapping = aes(color = cut), binwidth = 500)
```

Distribution of price by cut using `geom_boxplot()`:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = diamonds, mapping = aes(x = cut, y = price)) + geom_boxplot()
```

# Better quality diamonds are cheaper on average.

Many categorical variables are not ordered properly like fair < good < very good < premium < ideal. So we need  to reorder them to make a more informative display. One way to do this is with `reorder()` function
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot()
```

To make the trend easier to see, we can reorder class based on the median value of hwy.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = mpg) + geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy))
```

For long variable names, we can flip the axes:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = mpg) + geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) + coord_flip()
```

## Two categorical variables
To  visualise the covariation between categorical variables, you will need to count the number of observations for each combination. One way to do that is to rely on the built in `geom-count()`
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = diamonds) + geom_count(mapping = aes(x = cut, y = color))
```

We can also compute the count with dplyr
```{r, cache=TRUE, message=FALSE, warning=FALSE}
diamonds %>% 
  count(color, cut)
```

Then visualize with geom_tile() and the fill aesthetic:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
diamonds %>%
  count(color, cut) %>%
  ggplot(mapping = aes(x = color, y = cut)) + geom_tile(mapping = aes(fill = n))
```

With a scatterplot, we can see an exponential relationship between carat size and price of diamonds
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = diamonds) + geom_point(mapping = aes(x = carat, y = price))
```

Use the `alpha` aesthetic to add the transparency
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = diamonds) + geom_point(mapping = aes(x = carat, y = price), alpha = 1/100)
```

`geom_bin2d()` creates rectangular bins and `geom_hex()` creates hexagonal bins.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = smaller) + geom_bin2d(mapping = aes(x = carat, y = price))
ggplot(data = smaller) + geom_hex(mapping = aes(x = carat, y = price))
```

We could also bin carat and for each group display a boxplot.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data = smaller, mapping = aes(x = carat, y = price)) + geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)))
```

```
ggplot(data = faithful, mapping = aes(x = eruptions)) + geom_freqpoly(binwdth = 0.25)
```
can be written more concisely as:
```
ggplot(faithful, aes(eruptions)) + geom_freqpoly(binwidth = 0.25)
```

# DATA IMPORT

`read_csv()`
In this case, `read_csv()` uses the first line of the data for the column names.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
read_csv("a, b, c
         1, 2, 3
         4, 5, 6")
```

Sometimes thera are a few lines of metadata at the top of the file. We can use skip = n to skip the first n lines or use comment = "#" to drop all lines that start with e.g. '#'.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
read_csv("The first line of metadata
         The second line of metadata
         x, y, z
         1, 2, 3", skip = 2)
```
```{r, cache=TRUE, message=FALSE, warning=FALSE}
read_csv("# A comment I wnat to skip
         x, y, z
         1, 2, 3", comment = "#")
```

If the data does not have column names, we can use `col_names = FALSE` to tell `read_csv()` not to treat the first row as headings, and instead label them sequentially from x1 to xn.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
read_csv("1, 2, 3\n4, 5, 6", col_names = FALSE)
```

We can also pass col_names a character vector which will be used as the column names
```{r, cache=TRUE, message=FALSE, warning=FALSE}
read_csv("1, 2, 3\n4, 5, 6", col_names = c("x", "y", "z"))
```

`na` specifies the value or calues that are used to represent the missing values in the file.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
read_csv("a, b, c\n1, 2, .", na = ".")
```

`parse_*()` functions take a character vector and return a more specialised vector like a logical, integer or a date.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
str(parse_logical(c("TRUE", "FALSE", "NA")))
str(parse_integer(c("1", "2", "3")))
str(parse_date(c("2010-01-01", "1979-10-14")))
```

The first argument is a character vector to parse and the `na` argument specifies which strings should be treated as missing.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
parse_integer(c("1", "231", ".", "456"), na = ".")
```

`parse_number()` ignores non-numeric characters before and after the number. This is particularly useful for currencies and percentages., but also works to extract numbers embedded in text.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
parse_number("$100")
parse_number("20%")
parse_number("It cost $123.45")
parse_number("$123,456,789")
```

## Factors
R uses factors to represent categorical variables that have a known set of possible values. Give parse_factor() a vector of known levels to generate a warning whenver an unexpected value is present.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
fruit <- c("apple", "banana")
parse_factor(c("apple", "banana", "banananana"), levels = fruit)
```

## Parsing a file

R uses heursistics to figure out the type of each column.  We can emulate this process with a character vector using `guess_parser()` which returns the best guess and `parse_guess()` which uses that guess to parse the column.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
guess_parser("2010-10-01")
guess_parser("15:01")
guess_parser(c("TRUE", "FALSE"))
guess_parser(c("1", "5", "9"))
guess_parser(c("12,352,561"))
str(parse_guess("2010-01-01"))

```

## Gathering
used to tidy a dataset where 1999 and 2000 are column names. We want to put them in a single column called "year".
`tabel4a %>% gather(`1999`, `2000`, key = "year", value = "cases")`
Here, we need to use backticks for 1999 and 2000 because they are non-syntatic names or they do not start with a letter.

Similarly, we can use `gather()` to tidy table4b in a similar fashion. 
`table4b %>% gather(`1999`, `2000`, key = "year", value = "population")

To combine the tidied versions of table4a and table4b into a single tibble, we need to use `left_join()`
`left_join(tidy4a, tidy4b)`

## Spreading
It is the opposite of gathering. We can use it when an observation is scattered across multiple rows. 
`table2 %>% spread(key = type, value = count)`

## Separating
If the rate column containds both cases and population variables, we can separate it into two variables. 
`table3 %>% separate(rate, into = c("cases", "poulation"))`
By defualt, separate() will separate values wherever it sees an alphanumeric character. 
We could also write the code as:
`table2 %>% separate(rate, into = c("cases", "poulation"), sep = "/")`
separate() leaves the type of column as is. It not very useful in this case however, as those are actuually number. We can ask separate() to try and convert better types using convert = TRUE
`tabel3 %>% separate(rate, into = c("cases", "population"), convert = TRUE)

We can also separate the last two digits of each year.
`table3 %>% separate(year, into = c("century", "year"), sep = 2)`

## Unite
It is the inverse of separate. It combines multiple columns into a single column.
We can use unite() to rejoin century and year columns that we created in the last example.
`table5 %>% unite(new, century, year)`
The default will place an underscore (_) between the values from different columns. If we do not want any separator, we use sep = ''.
`table5 %>% unite(new, century, year, sep = "")

# MISSING VALUES
They can be missing in one of two possible ways:
Explicilty: flagged with NA, or Implicitly: simply not present in the data
```{r, cache=TRUE, message=FALSE, warning=FALSE}
stocks <- tibble(
  year = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
  qtr = c(    1,    2,    3,    4,    2,    3,     4),
  return = c(1.88, 0.59, 0.35,  NA, 0.92, 0.17, 2.66)
)
stocks
```
The return for the fourth quarter of 2015 is explicitly missing, whereas the return for the first quarter of 2016 is implicitly missing because it simply does not appear in the dataset.
We can make the implicit missing value explicit by putting years in the columns.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
stocks %>% spread(year, return)
```

We can set na.rm = TRUE in gather() to turn explicit missing values implicit:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
stocks %>%
  spread(year, return) %>%
  gather(year, return, `2015`:`2016`, na.rm = TRUE)
```

Another way to make missing values explicit in tidy data is `complete()`.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
stocks %>% complete(year, qtr)
```

Sometimes when a data source has been primarily used for data entry, missing values indicate that the previous value has been carried forward.  We can fill these missing values with `fill()`


# Case Study
```{r, cache=TRUE, message=FALSE, warning=FALSE}
tidyr::who
```

It looks like `country`, `iso2` and `iso3` are three variables that redundantly specify the country. `year` is clearly also a variable. We don't know what all the other columns are yet but given the structure in the variable names, these are likely to be values, not variables. So, we need to gather together all the columns from `new_sp_m014` to `newrel_f65`. We do not know what those values represent yet, so we will give them the generic name "key". We know the cells represent the count of cases so we will use the variable `cases`.

```{r, cache=TRUE, message=FALSE, warning=FALSE}
who1 <- who %>% 
  gather(new_sp_m014:newrel_f65, key = "key", value = "cases", na.rm = TRUE)
who1
```

We can get some hint of the structure of the values in the new `key` column by counting them. 
```{r, cache=TRUE, message=FALSE, warning=FALSE}
who1 %>%
  count(key)
```

We are going to replace the characters "newrel" with "new_rel" to make the variable names consistent.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
who2 <- who1 %>%
  mutate(key = stringr::str_replace(key, "newrel", "new_rel"))
who2
```

We can separate the values in each code with two passes of `separate()`. The first pass will split the codes at each underscore.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
who3 <- who2 %>%
  separate(key, c("new", "type", "sexage"), sep = "_")
who3
```

We might as well drop the `new` column because it is constant in the dataset. While we are dropping columns, we can also drop iso2 and iso3 since they are redundant.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
who3 %>% count(new)
who4 <- who3 %>% select(-new, -iso2, -iso3)
who4
```

Next we can separate sexage into sex and age by splitting after the first character.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
who5 <- who4 %>%
  separate(sexage, c("sex", "age"), sep = 1)
who5
```

# Relational Data

```{r, cache=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(nycflights13)
airlines
airports
planes
weather
```

To identify the primary keys in the tables, we can use `count()` and look for entries where n is greater than one:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
planes %>%
  count(tailnum) %>%
  filter(n>1)
weather %>%
  count(year, month, day, hour, origin) %>%
  filter(n>1)
```

## Mutating joins 
 `mutate()` allows us to combine variables from two tables.
 
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights
flights2 <- flights %>%
  select(year:day, hour, origin, dest, tailnum, carrier)
flights2
```

If we want to add full airline name to flights2 data, we can combine `airlines` and `flights2` dataframe with left_join():
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights2 %>%
  select(-origin, -dest) %>%
  left_join(airlines, by = "carrier")
```

We could have also obtained the same result with `mutate`
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights2 %>%
  select(-origin, -dest) %>%
  mutate(name = airlines$name[match(carrier, airlines$carrier)])
```

# Left join is the most widely used type of join: it preserves all entries in the left table.
The default `by = NULL` uses all variables that appear in both tables, the so called natural join. The flights and weather tables match on their common variables: year, month, day, hour and origin.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights2 %>%
  left_join(weather)
```

`flights` and `planes` have `year` variables but they mean different things, so we only want to join by `tailnum`.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights2 %>%
  left_join(planes, by="tailnum")
```

`base::merge()` can perform all types of mutating joins:
`inner_join(x, y)` ---> `merge(x, y)`
`left_join(x, y)` ---> `merge(x, y, all.x = TRUE)`
`right_join(x, y)` ---> `merge(x, y, all.y = TRUE)`
`full_joi(x, y)`---> `merge(x, y, all.x = TRUE, all.y = TRUE)`


# Strings
Use `writeLines()` to print a string
```{r, cache=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(stringr)
string1 <- "This is a string"
string2 <- 'If I want to include a "quote" inside a string, I use single quotes'
writeLines(string1)
writeLines(string2)
```

Multiple strings are often stored in a character vector which we can create with `c()`:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
c("one", "two", "three")
```

The Base R functions can be inconsistent, hence we should use the functions from `stringr` `str_length()` tells us the number of characters in a string.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
str_length(c("a", "R for data science", NA))
```

To combine two strings, we can use `str_c()`:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
str_c("x", "y")
str_c("x", "y", "z")
```

Use `sep` argument to control how they are separated:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
str_c("x", "y", sep = ", ")
```

## Subsetting strings()
As well as the string, `str_sub()` takes the start amd emd arguments which give the inclusive position of the substring.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
x <- c("Apple", "Banana", "Pear")
str_sub(x, 1, 3)
str_sub(x, -3, -1)
```


# FACTORS
We need the forcats package to be able to work with factors.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(forcats)
```


Imagine that we have a variable that records months:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
x1 <- c("Dec", "Apr", "Jan", "Mar")
```

It does not sort in a useful way:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
sort(x1)
```

We can solve this problem by creating a factor. To create a factor, we must start by creating a list of valid levels:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
month_levels <- c(
  "Jan", "Feb", "Mar", "Apr", "May", "Jun",
  "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
)
```

Now we can create a factor:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
y1 <- factor(x1, levels = month_levels)
y1
sort(y1)
```

```{r, cache=TRUE, message=FALSE, warning=FALSE}
gss_cat
gss_cat %>% count(race)
```

Bar chart:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(gss_cat, aes(race)) + geom_bar()
```

By default, ggplot drops levels that do not have any values. We can force them to display with:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(gss_cat, aes(race)) + geom_bar() + scale_x_discrete(drop = FALSE)
```

Suppose we want to explore the average number of hours spent eatching TV per day across religions:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
relig_summary <- gss_cat %>%
  group_by(relig) %>%
  summarise(
    tvhours = mean(tvhours, na.rm = TRUE),
    n = n()
  )
ggplot(relig_summary, aes(tvhours, relig)) + geom_point()
```

There is no overall pattern. We can improve the reordering by usinf `fct_reorder()`:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(relig_summary, aes(tvhours, fct_reorder(relig, tvhours))) + geom_point()
```

We want to plot how average age varies across reported income levels:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
rincome_summary <- gss_cat %>%
  group_by(rincome) %>%
  summarise(
    age = mean(age, na.rm = TRUE),
    n = n()
    )
ggplot(rincome_summary, aes(age, fct_reorder(rincome, age))) + geom_point()
```

It makes more sense to put not applicable to the front. To do this, we can use `fct_relevel()`:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(rincome_summary, aes(age, fct_relevel(rincome, "Not applicable"))) + geom_point()
```

For barplots, we can use `fct)infreq()` to order levels in increasing frequency by combining it with fct_rev():
```{r, cache=TRUE, message=FALSE, warning=FALSE}
gss_cat %>%
  mutate(marital = marital %>% fct_infreq() %>% fct_rev()) %>%
  ggplot(aes(marital)) + geom_bar()
```

`fct_recode()` allows us to recode or change the value of each level:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
gss_cat %>% count(partyid)
```

Here the levels are terse and inconsistent. We can make them longer:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
gss_cat %>% 
  mutate(partyid = fct_recode(partyid, 
                              "Republican, strong" = "Strong republican",
                              "Republican, weak" = "Not str republican",
                              "Independent, near rep" = "Ind, near rep", 
                              "Independent, near dem" = "Ind, near dem",
                              "Democrat, weak" = "Not str democrat",
                              "Democrat, strong" = "Strong democrat")) %>%
  count(partyid)
```

To combine groups, we can assign multiple old levels to the same new level:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
gss_cat %>% 
  mutate(partyid = fct_recode(partyid, 
                              "Republican, strong" = "Strong republican",
                              "Republican, weak" = "Not str republican",
                              "Independent, near rep" = "Ind, near rep", 
                              "Independent, near dem" = "Ind, near dem",
                              "Democrat, weak" = "Not str democrat",
                              "Democrat, strong" = "Strong democrat",
                              "Other" = "No answer",
                              "Other" = "Don't know",
                              "Other" = "Other party")) %>%
  count(partyid)
```

We can use `fct_collpase()` to collapse a lot of levels:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
gss_cat %>%
  mutate(partyid = fct_collapse(partyid,
                                other = c("No answer", "Don't know", "Other party"),
                                rep = c("Strong republican", "Not str republican"),
                                ind = c("Ind,near rep", "Independent", "Ind,near dem"),
                                dem = c("Not str democrat", "Strong democrat")
                                )) %>%
  count(partyid)
```

# DATETIME

`lubridate` is the package that makes it easier to work with dates and times.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(nycflights13)
ymd("2017-01-31")
mdy("January 31st, 2017")
dmy("31-Jan-2017")
```

## From individual components:
Sometimes, date-time is spread across multiple columns:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights %>% select(year, month, day, hour, minute)
```

To create date-time:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights %>%
  select(year, month, day, hour, minute) %>%
  mutate(departure = make_datetime(year, month, day, hour, minute))
```

The times are represented in a slightly odd format, so we can use modulo arithmetic to pull put the hour and minute components.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
make_datetime_100 <- function(year, month, day, time){
  make_datetime(year, month, day, time %/% 100, time %% 100)
}
flights_dt <- flights %>%
  filter(!is.na(dep_time), !is.na(arr_time)) %>%
  mutate(
    dep_time = make_datetime_100(year, month, day, dep_time),
    arr_time = make_datetime_100(year, month, day, arr_time),
    sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),
    sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)
  )%>%
  select(origin, dest, ends_with("delay"), ends_with("time"))
flights_dt
```

We can visualise the distribution of departure times across the year:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights_dt %>% 
  ggplot(aes(dep_time)) + 
  geom_freqpoly(binwidth = 86400)
```

or within a single day:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights_dt %>%
  filter(dep_time < ymd(20130102)) %>%
  ggplot(aes(dep_time)) + 
  geom_freqpoly(binwidth = 600)
```

We can use `wday()` to see that more flights depart during the week than on weekend:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights_dt %>% 
  mutate(wday = wday(dep_time, label = TRUE)) %>%
  ggplot(aes(x = wday)) + geom_bar()
```

It looks like flights leaving in minutes 20-30 and 50-60 have much lower delays than rest of the hour.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights_dt %>%
  mutate(minute = minute(dep_time)) %>%
  group_by(minute) %>%
  summarise(
    avg_delay = mean(arr_delay, na.rm = TRUE),
    n= n()) %>%
  ggplot(aes(minute, avg_delay)) + geom_line()
```

We can use `update()` to show the distribution of flights across the course of the day for everyday of the year:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
flights_dt %>%
  mutate(dep_hour = update(dep_time, yday = 1)) %>%
  ggplot(aes(dep_hour)) + 
  geom_freqpoly(binwidth = 300)
```

# VECTORS

```{r, cache=TRUE, message=FALSE, warning=FALSE}
typeof(letters)
typeof(1:10)
x <- list("a", "b", 1:10)
length(x)
```

## Logical
They are the simplest type of atomic vectors because they can only take three possible values: FALSE, TRUE and NA:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
1:10 %% 3 == 0
c(TRUE, TRUE, FALSE, NA)
```

## Numeric
Integer and double are known collectively as numeric vectors. In R, numbers are doubles by default. To make an integer, place an L after the number.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
typeof(1)
typeof(1L)
1.5L
```

## Naming vectors
```{r, cache=TRUE, message=FALSE, warning=FALSE}
c(x = 1, y = 2, z = 4)
set_names(1:3, c("a", "b", "c"))
```

## Subsetting vectors

`[.[` is the subsetting function and is called as x[a].
Subsetting with positive integers keeps the elements at those positions:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
x <- c("one", "two", "three", "four", "five")
x[c(3, 2, 5)]
```

By repeating a position, we can make a longer output than input:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
x[c(1, 1, 5, 5, 5, 2)]
```

Negative values drop the elements at the specified posiitons:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
x[c(-1, -3, -5)]
```

Subsetting with a logical vector keeps all values corresponding to a TRUE value.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
x <- c(10, 3, NA, 5, 8, 1, NA)

# All missing values of x
x[!is.na(x)]

# All even or missing values of x
x[x %% 2 ==  0]
```

## Recursive vectors or lists

```{r, cache=TRUE, message=FALSE, warning=FALSE}
x <- list(1, 2, 3)
```

```{r, cache=TRUE, message=FALSE, warning=FALSE}
str(x)
```

```{r, cache=TRUE, message=FALSE, warning=FALSE}
x_named <- list(a = 1, b = 2, c = 3)
str(x_named)
```

Unlike atomic vectors, lists can contain a mix of objects:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
y <- list("a", 1L, 1.5, TRUE)
str(y)
```

Lists can even contain other lists
```{r, cache=TRUE, message=FALSE, warning=FALSE}
z <- list(list(1, 2), list(3, 4))
str(z)
```

## Subsetting a list
```{r, cache=TRUE, message=FALSE, warning=FALSE}
a <- list(a = 1:3, b = "a string", c = pi, d = list(-1, -5))
```

[ extracts a sublist. The result of which is always a list.

```{r, cache=TRUE, message=FALSE, warning=FALSE}
str(a[1:2])
str(a[4])
```

`[[` extracts a single component from a list. It removes a level of hierarchy from the list.
```{r, cache=TRUE, message=FALSE, warning=FALSE}
str(a[[1]])
str(a[[4]])
```


# Iteration

## For loops
```{r, cache=TRUE, message=FALSE, warning=FALSE}
df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10), 
  d = rnorm(10)
)
df
```

To compute the median of each column, we could do it like this:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
median(df$a)
median(df$b)
median(df$c)
median(df$d)
```

Or we could use a for loop:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
output <- vector("double", ncol(df))
for (i in seq_along(df)) {
  output[[i]] <- median(df[[i]])
}
output
```